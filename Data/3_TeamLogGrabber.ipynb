{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Team Log Grabber</h1>\n",
    "<p>This notebook grabs the regular season logs for every hockey team from 1990 on</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as r\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>First Grab a list of teams</h2>\n",
    "<p>All the hockey teams are linked via a link /teams/XXX/history.html.  Defunct teams (or teams like the Atlanta Thrashers which moved to Winnipeg) are listed as the team to which they transfered to.  Before getting the gamelogs, we first scrap the team abbreviations which change from season to season.  This, the team names, and the gamelog links for the season are stored in a DataFrame.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first get a link to their histories\n",
    "\n",
    "link_list = [] #list of links to the respective teams\n",
    "url = 'https://www.hockey-reference.com'\n",
    "t = r.get(url+'/teams')\n",
    "soup = bs(t.text, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "for l in links:\n",
    "    if 'history.html' in l['href']:\n",
    "        link_list.append(l['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now create a dataframe consisting of the season, the team name, team abbreviation and the link season_log\n",
    "teamDataFrame = pd.DataFrame(columns=['Season','team_name','team_abbr','link'])\n",
    "\n",
    "for link in link_list:\n",
    "    page = r.get(url+link)\n",
    "    soup = bs(page.text, 'html.parser')\n",
    "    links = soup.find_all('table')\n",
    "    for row in links[0].find_all('tr')[1:]:\n",
    "\n",
    "        #get season & link\n",
    "        main_c = row.find_all('th')[0]\n",
    "        link = main_c.find_all('a')\n",
    "\n",
    "        if len(link)>0:\n",
    "            link = link[0]['href'] #this gets the link to team main page\n",
    "\n",
    "        if main_c['data-stat']=='season':\n",
    "            season = main_c.text #this gets the season\n",
    "        for c in row.find_all('td'):\n",
    "            if c['data-stat']=='team_name':\n",
    "                tname = c.text.strip('*')   #here's the team name\n",
    "        abbr = re.search(r'teams\\/(\\w{3})\\/',link)[1]  #the abbreviation is extracted from the link\n",
    "        team_gamelog = 'teams/'+abbr+'/'+str(int(season[:4])+1)+'_gamelog.html'\n",
    "\n",
    "        #record if the season is after 1990\n",
    "        if int(season[:4])<1990:   #we don't care before 1990\n",
    "            break\n",
    "        else:\n",
    "            teamDataFrame = teamDataFrame.append(dict(zip(teamDataFrame.columns,[season,tname,abbr,team_gamelog])),ignore_index=True)\n",
    "\n",
    "teamDataFrame.to_csv('team_gamelog_list.txt','\\t')\n",
    "teamDataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Now Grab the Gamelogs</h2>\n",
    "<p>Now I can use the links from above to grab the game logs which I'll store as a txt under the unique identifier team_abbr/season (for example ANA2020)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamelogger(link):\n",
    "    \"\"\"\n",
    "    Grabs the game logs for each of the link entered and returned as a DataFrame\n",
    "    Input:  (string) gamelog link\n",
    "    Output: (dataframe) gamelog data (excluding playoffs) for that year\n",
    "    \"\"\"\n",
    "    glogs = pd.DataFrame()\n",
    "    #for every year after 1990 (1991 is the 1990-1991 season), grab the gamelogs\n",
    "    column_names = []\n",
    "    page = r.get('https://hockey-reference.com/'+link)\n",
    "    soup = bs(page.text,'html.parser')\n",
    "\n",
    "    for eachitem in soup.find_all('tr',id=True): #for each row in table\n",
    "        rowdata = []\n",
    "        #only count regular season games\n",
    "        if eachitem['id'][11:13] == 'rs':\n",
    "            for eachc in eachitem.find_all('td'): #for each column in row\n",
    "                if glogs.empty:\n",
    "                    column_names.append(eachc['data-stat'])\n",
    "                rowdata.append(eachc.text)\n",
    "            if glogs.empty:\n",
    "                glogs = pd.DataFrame(columns=column_names)\n",
    "            glogs = glogs.append(dict(zip(glogs.columns,rowdata)), ignore_index=True) \n",
    "    return glogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,team in teamDataFrame.iterrows():\n",
    "    try:\n",
    "        log = gamelogger(team['link'])\n",
    "        log.to_csv('team_gamelogs\\\\'+team['team_abbr']+'_'+str(int(team['Season'][:4])+1)+'.txt','\\t')\n",
    "    except:\n",
    "        print(\"Error with row %d, link %s\" % (i,team['link']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
